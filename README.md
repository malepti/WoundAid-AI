# ğŸ©º WoundAid AI

WoundAid AI is an open-source AI assistant that analyzes images of wounds and provides first aid suggestions. It uses a vision-language model (BLIP-2) to describe the injury and a large language model (Falcon-7B-Instruct) to suggest first aid â€” all completely free and runnable on Google Colab.

---

## ğŸ” Features

- ğŸ“¸ Upload wound or injury image
- ğŸ¤– Auto-describe the wound using BLIP-2
- ğŸ’¬ Get natural first aid suggestions from Falcon-7B-Instruct
- ğŸŒ 100% free, open-source, and no paid API keys required
- ğŸš€ Easy to run on Google Colab with GPU support

---

## ğŸ“Š Architecture


---

## ğŸ§  Models Used

### 1. **BLIP-2 (Salesforce/blip2-opt-2.7b)**
- Role: Image captioning â€” converts uploaded image into wound description
- Link: [https://huggingface.co/Salesforce/blip2-opt-2.7b](https://huggingface.co/Salesforce/blip2-opt-2.7b)

### 2. **Falcon-7B-Instruct (tiiuae/falcon-7b-instruct)**
- Role: Large language model â€” takes caption and outputs treatment suggestion
- Link: [https://huggingface.co/tiiuae/falcon-7b-instruct](https://huggingface.co/tiiuae/falcon-7b-instruct)

---

## ğŸ“¦ Requirements

Install these in your Colab notebook (they are included in the code already):

```bash
pip install -q transformers accelerate torch torchvision timm bitsandbytes
woundaid-ai/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ woundaid_colab.ipynb     # Colab Notebook (optional)
â”œâ”€â”€ requirements.txt         # Optional dependency file
â””â”€â”€ sample_inputs/           # Sample wound images (optional)
